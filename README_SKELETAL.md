# Skeletal Violence Detection System

## ğŸ¯ Overview

A privacy-preserving violence detection system using skeletal pose estimation and LSTM networks.

### Performance
- **Accuracy**: 70.5%
- **Violence Recall**: 87% (excellent at catching violent behavior)
- **Model Size**: ~1M parameters (25x smaller than ResNet50+LSTM)
- **Approach**: Motion-based (skeletal keypoints) instead of appearance-based

## ğŸ—ï¸ Architecture

```
Video Frame â†’ YOLOv8-Pose â†’ Skeleton (17 keypoints)
                â†“
          Feature Encoder (99 â†’ 256)
                â†“
        Bidirectional LSTM (2 layers)
                â†“
          Classifier (Violence/Normal)
```

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Run Violence Detection

```bash
# Activate virtual environment (if using)
source venv/Scripts/activate  # Windows
# source venv/bin/activate     # Linux/Mac

# Run on video file
cd app
python main_skeletal.py
```

### 3. Configure Video Source

Edit the `VIDEO_SOURCE` path in `main_skeletal.py`:

```python
VIDEO_SOURCE = r"path/to/your/video.mp4"
```

## ğŸ“ Project Structure

```
Violence-Detection-System/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main_skeletal.py          # ğŸŒŸ Main inference script (NEW)
â”‚   â”œâ”€â”€ model.py                  # ğŸŒŸ Skeletal LSTM model (NEW)
â”‚   â”œâ”€â”€ skeleton_extractor.py    # ğŸŒŸ YOLOv8-Pose extractor (NEW)
â”‚   â”œâ”€â”€ yolov8n.pt               # YOLOv8 person detection
â”‚   â”œâ”€â”€ yolov8n-pose.pt          # ğŸŒŸ YOLOv8-Pose model (NEW)
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ weights/
â”‚   â””â”€â”€ best_skeleton_model.pth  # ğŸŒŸ Trained model (70.5% accuracy)
â”‚
â”œâ”€â”€ training/
â”‚   â””â”€â”€ skeletal_violence_detection_rwf2000.ipynb  # Training notebook
â”‚
â”œâ”€â”€ Output/
â”‚   â”œâ”€â”€ training_results.json    # Training metrics
â”‚   â”œâ”€â”€ confusion_matrix.png     # Performance visualization
â”‚   â””â”€â”€ training_history.png     # Training curves
â”‚
â”œâ”€â”€ archive/
â”‚   â””â”€â”€ old_resnet_lstm/         # Old ResNet50+LSTM model (50% accuracy)
â”‚
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

### Model Parameters (in `main_skeletal.py`):

```python
SEQUENCE_LENGTH = 16          # Number of frames for LSTM
CONFIDENCE_THRESHOLD = 0.65   # Violence detection threshold (0-1)
SKIP_INFERENCE = 3            # Run AI every N frames
FRAME_STRIDE = 2              # Sample every Nth frame
MOTION_THRESHOLD = 3.0        # Minimum motion to trigger
PERSON_CONFIDENCE = 0.45      # Person detection confidence
TEMPORAL_SMOOTHING = 5        # Predictions to smooth
```

## ğŸ“Š Model Comparison

| Feature | Old Model (ResNet50+LSTM) | New Model (Skeletal) |
|---------|--------------------------|---------------------|
| **Accuracy** | 50% | **70.5%** âœ… |
| **Violence Recall** | 0% | **87%** âœ… |
| **Model Size** | ~25M params | **~1M params** âœ… |
| **Input** | Raw RGB frames | Skeletal keypoints |
| **Privacy** | Captures faces/identity | **Privacy-preserving** âœ… |
| **Speed** | Slower (large model) | **Faster** âœ… |

## ğŸ“ How It Works

1. **Skeleton Extraction** (YOLOv8-Pose)
   - Detects humans in frame
   - Extracts 17 COCO keypoints per person
   - Keypoints: nose, eyes, ears, shoulders, elbows, wrists, hips, knees, ankles
   
2. **Feature Encoding**
   - Compresses 99 features (17Ã—3 keypoints + padding)
   - 2-layer MLP: 99 â†’ 512 â†’ 256
   
3. **Temporal Modeling** (Bidirectional LSTM)
   - Processes 16-frame sequences
   - 2 layers, 256 hidden units
   - Looks at past AND future frames
   
4. **Classification**
   - Binary output: Violence / Non-Violence
   - Temporal smoothing for stability

## ğŸ¯ Use Cases

âœ… **Surveillance Systems** - Real-time violence detection in public spaces  
âœ… **School Safety** - Monitor playgrounds and hallways  
âœ… **Prison Monitoring** - Detect fights and altercations  
âœ… **Sports Analytics** - Detect fouls and aggressive behavior  
âœ… **Content Moderation** - Filter violent videos on platforms  

## ğŸ›¡ï¸ Privacy Benefits

Unlike appearance-based models (ResNet50), this skeletal approach:
- âœ… Does NOT capture faces or identifying features
- âœ… Only tracks body movements and poses
- âœ… Cannot reconstruct original appearance
- âœ… GDPR/privacy-friendly for surveillance

## ğŸ“ˆ Training Details

- **Dataset**: RWF-2000 (2,000 real-world fight videos)
- **Training Time**: ~18 minutes on GPU
- **Epochs**: 19 (early stopping at epoch 12)
- **Best F1-Score**: 74.68%
- **ROC AUC**: 0.68

## ğŸ”¬ Technical Details

**Skeletal Keypoints (17 COCO points):**
```
0: Nose          6: Right Shoulder  12: Right Hip
1: Left Eye      7: Left Elbow      13: Left Knee
2: Right Eye     8: Right Elbow     14: Right Knee
3: Left Ear      9: Left Wrist      15: Left Ankle
4: Right Ear     10: Right Wrist    16: Right Ankle
5: Left Shoulder 11: Left Hip
```

## ğŸ› Troubleshooting

**Model not loading?**
- Check that `weights/best_skeleton_model.pth` exists
- Verify the path in `main_skeletal.py`

**Low performance?**
- Reduce `SKIP_INFERENCE` value (more frequent predictions)
- Lower `CONFIDENCE_THRESHOLD` (more sensitive)
- Adjust `TEMPORAL_SMOOTHING` (reduce for faster response)

**No person detected?**
- Lower `PERSON_CONFIDENCE` threshold
- Check lighting conditions in video
- Ensure people are visible in frame

## ğŸ“ Citation

If you use this model in your research, please cite:

```
Skeletal Violence Detection System
Based on YOLOv8-Pose and Bidirectional LSTM
Trained on RWF-2000 dataset
Accuracy: 70.5%, Violence Recall: 87%
```

## ğŸ“„ License

This project is for educational and research purposes.

## ğŸ¤ Contributing

Contributions welcome! Areas for improvement:
- Add more datasets (AIRTLAB, Real Life Violence)
- Implement attention mechanisms
- Try Graph Neural Networks (GNN)
- Add multi-person aggregation
- Improve temporal modeling

---

**Created**: January 2026  
**Model Version**: v1.0  
**Status**: âœ… Production Ready
